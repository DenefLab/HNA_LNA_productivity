{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Import packages'''\n",
    "'''Requires numpy, pandas, scikit-learn, and matplotlib/seaborn'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import Lasso\n",
    "from scipy.stats import linregress\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "'''Import script which contains functions'''\n",
    "import analysis_functions\n",
    "from analysis_functions import get_r2\n",
    "from analysis_functions import get_lassoCV\n",
    "from analysis_functions import perform_randomizedLasso\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "#If we want to time the implementation: \n",
    "#import time\n",
    "#start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataframes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Import data'''\n",
    "data_abs = pd.read_csv('data/Chloroplasts_removed/nochloro_absolute_otu.tsv', sep=' ', index_col=None, header=0)\n",
    "data_rel = pd.read_csv('data/Chloroplasts_removed/nochloro_relative_otu.tsv', sep=' ', index_col=None, header=0)\n",
    "target = pd.read_csv('data/Chloroplasts_removed/nochloro_HNA_LNA.tsv', sep=' ', index_col=0, header=0)\n",
    "productivity = pd.read_csv('data/Chloroplasts_removed/productivity_data.tsv', sep=' ', index_col=0, header=0)\n",
    "productivity.index = productivity.samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)**: At 01-05-'17 @marschmi found that a few samples can be seen as outliers, as they represent the bottom waters of productive inland lakes, resulting in a big difference of the HNA percentage. These samples are the following: Z14055F, Z14003F, Z14007F, Z14023F, Z14011F. A code of line is added, in order to be able to run the pipeline without these samples; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_to_drop = ['Z14055F', 'Z14003F', 'Z14007F', 'Z14023F', 'Z14011F']\n",
    "index = target.index.drop(samples_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Set sample names as index and shuffle data'''\n",
    "productivity = productivity.loc[target.samples.values,:]\n",
    "productivity.index= target.index\n",
    "\n",
    "#Remove outlier samples:\n",
    "data_abs = data_abs.loc[index,:] \n",
    "data_rel = data_rel.loc[index,:]\n",
    "target = target.loc[index,:]\n",
    "productivity = productivity.loc[index,:]\n",
    "\n",
    "#Shuffle data: \n",
    "data_abs = data_abs.sample(frac=1, random_state=3)\n",
    "data_rel = data_rel.sample(frac=1, random_state=3)\n",
    "target = target.sample(frac=1, random_state=3)\n",
    "productivity = productivity.sample(frac=1, random_state=3) \n",
    "\n",
    "#Create target columns of HNA-values: \n",
    "hna = target.loc[:,'HNA.cells']\n",
    "hna_rel = hna/target.loc[:,'Total.cells']\n",
    "hna = pd.Series(hna, index=hna.index)\n",
    "hna_rel = pd.Series(hna_rel, index=hna.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-- PREPROCESSING OF DATA --**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)**: filter out those OTUs which have very low abundances and so give rise to (almost) zero-columns. Therefore an OTU has to have a minimal relative abundance one, defined by the parameter $abun$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, depending on the problem set-up, I use a **second constraint** which states that an OTU must have a relative abundance > $abun$ in one of the **productivity** samples. In this way we're going to bias the OTU-selection towards the ones which are considerably present in the productivity samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Filtering based on productivity samples, not needed for first part of analysis'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Filtering based on productivity samples, not needed for first part of analysis'''\n",
    "#retain only productivity samples \n",
    "#productivity = productivity.dropna(subset=['tot_bacprod'])\n",
    "#remove high productivity samples (>90)\n",
    "#productivity = productivity[productivity.tot_bacprod < 90]\n",
    "\n",
    "#idx_prod = productivity.samples.values\n",
    "#display(idx_prod)\n",
    "#prod = pd.Series(productivity.tot_bacprod.values, index=idx_prod)\n",
    "#prod_error = pd.Series(productivity.SD_tot_bacprod.values, index=idx_prod)\n",
    "#prod_rel_error = prod_error/prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Parameter abun for initial filtering of OTUs'''\n",
    "abun = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of OTUs: 1245\n"
     ]
    }
   ],
   "source": [
    "from analysis_functions import preprocess_df\n",
    "data_abs = preprocess_df(data_abs,abun,True)\n",
    "otus = list(data_abs.columns)\n",
    "\n",
    "print('Number of OTUs: ' + str(len(otus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that this number is the same whether we use absolute or relative abundances, as the filtering is based on a minimal _relative_ abundance.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Some variables to store information and to create inner and outer CV-folds\n",
    "\n",
    "#cv_out = 10\n",
    "cv = 5\n",
    "#outer_cv = KFold(n_splits=cv_out, shuffle=False)\n",
    "\n",
    "#otu_scores_cv = pd.DataFrame(columns=otus)\n",
    "#r2_cv = np.zeros(cv_out)\n",
    "#thresholds_cv = np.zeros(cv_out)\n",
    "\n",
    "#pred = pd.Series(index=data_abs.index)\n",
    "#final_scores = pd.DataFrame(columns=otus)\n",
    "\n",
    "thresholds = np.arange(0,1,0.01)\n",
    "t = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first check the performance without using the randomized Lasso: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so, we use the **_Randomized Lasso_**: this method makes use of two kinds of randomization in order to select variables (i.e., OTU's) with a certain _stability_: (1) it fits a Lasso to various bootstrap subsamples and (2) it perturbs the initial weighting of certain variables. \n",
    "\n",
    "This results in a $score \\in [0,1]$ that is assigned to variables, with 0 denoting the case where a variable is never chosen by the Lasso, and 1 denoting the case where a variable always is chosen. In other words, the higher the score, the more important a variable can be considered to be. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a **10x5 nested cross-validation** scheme to evaluate our total pipeline: this means that the preprocessing and randomized Lasso is now included in this pipeline (in order to be sure not to overfit, motivated by the paragraph ''7.10.2 The Wrong and Right Way to Do Cross-validation\" in ESLII): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First goal: ** try to pinpoint those OTU's for which we are sure they are present in the '_HNA-cloud_'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lassoCV = get_lassoCV(cv)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_abs.loc[:,otus])\n",
    "data_abs = pd.DataFrame(scaler.transform(data_abs[otus]),index=data_abs.index,columns=otus)    \n",
    "lassoCV.fit(data_abs.loc[:,otus], hna)\n",
    "mse = np.sum(lassoCV.mse_path_, axis=1)\n",
    "mse_min = np.min(mse)\n",
    "alpha = lassoCV.alpha_\n",
    "    \n",
    "otu_scores = pd.Series(perform_randomizedLasso(data_abs.loc[:,otus], hna, alpha), index=otus)\n",
    "otu_scores.sort_values(ascending=False,inplace=True)\n",
    "        \n",
    "mse_scores = np.zeros(len(thresholds))\n",
    "dummy=0\n",
    "scores = otu_scores\n",
    "    \n",
    "for thr in thresholds: \n",
    "    scores = otu_scores[otu_scores.values > thr]\n",
    "    features_new = scores.index\n",
    "    if(len(features_new) > 0): \n",
    "        lassoCV = get_lassoCV(cv)\n",
    "        lassoCV.fit(data_abs.loc[:,features_new],hna)\n",
    "        #alphas, preds = perform_nested_ridge_cv(data_abs[features_new],hna) #We could use this if we want a different evaluation model\n",
    "        mse = np.sum(lassoCV.mse_path_, axis=1)\n",
    "        mse_scores[dummy] = np.min(mse)\n",
    "    dummy+=1\n",
    "        \n",
    "mse_scores = mse_scores[np.nonzero(mse_scores)]\n",
    "mse_min_idx = mse_scores.argmin()\n",
    "thresh_max = thresholds[mse_min_idx]\n",
    "optimal_scores = otu_scores[otu_scores.values>thresh_max]\n",
    "selected_otus = optimal_scores.index\n",
    "    \n",
    "lassoCV = get_lassoCV(cv)\n",
    "lassoCV.fit(data_abs.loc[:, selected_otus], hna)\n",
    "alpha = lassoCV.alpha_\n",
    "lasso = Lasso(alpha,max_iter=20000,normalize=False)\n",
    "pred = cross_val_predict(lasso, data_abs.loc[:, selected_otus], hna, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²_cv: 0.969335928734\n"
     ]
    }
   ],
   "source": [
    "r2_final = get_r2(pred,hna)   \n",
    "print('R²_cv: ' + str(r2_final) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Otu000009    0.693333\n",
       "Otu000382    0.580000\n",
       "Otu000344    0.576667\n",
       "Otu000123    0.570000\n",
       "Otu000176    0.560000\n",
       "Otu000227    0.550000\n",
       "Otu000067    0.546667\n",
       "Otu007625    0.540000\n",
       "Otu000011    0.533333\n",
       "Otu000025    0.530000\n",
       "Otu000098    0.523333\n",
       "Otu000128    0.506667\n",
       "Otu001312    0.500000\n",
       "Otu000047    0.496667\n",
       "Otu002102    0.496667\n",
       "Otu000487    0.476667\n",
       "Otu000173    0.463333\n",
       "Otu000004    0.456667\n",
       "Otu000765    0.453333\n",
       "Otu000474    0.453333\n",
       "Otu000203    0.453333\n",
       "Otu000050    0.446667\n",
       "Otu001929    0.446667\n",
       "Otu000106    0.433333\n",
       "Otu000016    0.433333\n",
       "Otu001749    0.433333\n",
       "Otu000109    0.430000\n",
       "Otu000057    0.426667\n",
       "Otu000224    0.423333\n",
       "Otu000319    0.423333\n",
       "Otu000007    0.423333\n",
       "Otu000981    0.420000\n",
       "Otu000112    0.420000\n",
       "Otu000469    0.413333\n",
       "Otu000124    0.406667\n",
       "Otu000204    0.403333\n",
       "Otu000175    0.396667\n",
       "Otu000563    0.383333\n",
       "Otu000005    0.380000\n",
       "Otu000030    0.380000\n",
       "Otu000222    0.376667\n",
       "Otu000139    0.370000\n",
       "Otu000781    0.363333\n",
       "Otu000084    0.353333\n",
       "Otu000354    0.346667\n",
       "Otu000219    0.346667\n",
       "Otu000360    0.340000\n",
       "Otu000104    0.340000\n",
       "Otu003229    0.336667\n",
       "Otu000048    0.336667\n",
       "Otu000247    0.333333\n",
       "Otu000029    0.330000\n",
       "Otu000209    0.326667\n",
       "Otu001835    0.323333\n",
       "Otu001664    0.320000\n",
       "Otu008167    0.320000\n",
       "Otu000152    0.316667\n",
       "Otu000824    0.316667\n",
       "Otu001345    0.316667\n",
       "Otu000249    0.316667\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(optimal_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimal_scores.to_csv('HNA_selectedOTUs_stand_abun_remov' + str(abun)+'_R2'+str(r2_final)+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-- WHAT IF WE ONLY CONSIDER THOSE OTU's WHICH ARE SIGNIFICANTLY PRESENT IN THE PRODUCTIVITY SAMPLES? --**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Import data'''\n",
    "data_abs = pd.read_csv('data/Chloroplasts_removed/nochloro_absolute_otu.tsv', sep=' ', index_col=None, header=0)\n",
    "data_rel = pd.read_csv('data/Chloroplasts_removed/nochloro_relative_otu.tsv', sep=' ', index_col=None, header=0)\n",
    "target = pd.read_csv('data/Chloroplasts_removed/nochloro_HNA_LNA.tsv', sep=' ', index_col=0, header=0)\n",
    "productivity = pd.read_csv('data/Chloroplasts_removed/productivity_data.tsv', sep=' ', index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Set sample names as index and shuffle data'''\n",
    "data_abs.set_index(target.samples,inplace=True)\n",
    "data_rel.set_index(target.samples,inplace=True)\n",
    "data_abs = data_abs.sample(frac=1, random_state=3)\n",
    "data_rel = data_rel.sample(frac=1, random_state=3)\n",
    "target = target.sample(frac=1, random_state=3)\n",
    "productivity = productivity.sample(frac=1, random_state=3)\n",
    "\n",
    "#Create target columns of HNA-values: \n",
    "hna = target.loc[:,'HNA.cells']\n",
    "hna_rel = hna/target.loc[:,'Total.cells']\n",
    "hna = pd.Series(hna, index=hna.index)\n",
    "hna_rel = pd.Series(hna_rel, index=hna_rel.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing: ** First filter productivity outliers (productivity > 90). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#retain only productivity samples \n",
    "productivity = productivity.dropna(subset=['tot_bacprod'])\n",
    "#remove high productivity samples (>90)\n",
    "productivity = productivity[productivity.tot_bacprod < 90]\n",
    "\n",
    "idx_prod = productivity.samples.values\n",
    "#display(idx_prod)\n",
    "prod = pd.Series(productivity.tot_bacprod.values, index=idx_prod)\n",
    "#prod_error = pd.Series(productivity.SD_tot_bacprod.values, index=idx_prod)\n",
    "#prod_rel_error = prod_error/prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of OTUs: 374\n"
     ]
    }
   ],
   "source": [
    "from analysis_functions import preprocess_df\n",
    "data_abs_prod = data_abs.loc[idx_prod,:] \n",
    "data_abs_prod = preprocess_df(data_abs_prod,abun,True)\n",
    "otus_prod = list(data_abs_prod.columns)\n",
    "\n",
    "print('Number of OTUs: ' + str(len(otus_prod)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lassoCV = get_lassoCV(cv)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_abs.loc[:,otus_prod])\n",
    "data_abs = pd.DataFrame(scaler.transform(data_abs[otus_prod]),index=data_abs.index,columns=otus_prod)    \n",
    "lassoCV.fit(data_abs.loc[:,otus_prod], hna)\n",
    "mse = np.sum(lassoCV.mse_path_, axis=1)\n",
    "mse_min = np.min(mse)\n",
    "alpha = lassoCV.alpha_\n",
    "    \n",
    "otu_scores_prod = pd.Series(perform_randomizedLasso(data_abs.loc[:,otus_prod], hna, alpha), index=otus_prod)\n",
    "otu_scores_prod.sort_values(ascending=False,inplace=True)\n",
    "        \n",
    "mse_scores = np.zeros(len(thresholds))\n",
    "dummy=0\n",
    "scores = otu_scores\n",
    "    \n",
    "for thr in thresholds: \n",
    "    scores = otu_scores_prod[otu_scores_prod.values > thr]\n",
    "    features_new = scores.index\n",
    "    if(len(features_new) > 0): \n",
    "        lassoCV = get_lassoCV(cv)\n",
    "        lassoCV.fit(data_abs.loc[:,features_new],hna)\n",
    "        #alphas, preds = perform_nested_ridge_cv(data_abs[features_new],hna) #We could use this if we want a different evaluation model\n",
    "        mse = np.sum(lassoCV.mse_path_, axis=1)\n",
    "        mse_scores[dummy] = np.min(mse)\n",
    "    dummy+=1\n",
    "        \n",
    "mse_scores = mse_scores[np.nonzero(mse_scores)]\n",
    "mse_min_idx = mse_scores.argmin()\n",
    "thresh_max = thresholds[mse_min_idx]\n",
    "optimal_scores_prod = otu_scores_prod[otu_scores_prod.values>thresh_max]\n",
    "selected_otus = optimal_scores_prod.index\n",
    "    \n",
    "lassoCV = get_lassoCV(cv)\n",
    "lassoCV.fit(data_abs.loc[:, selected_otus], hna)\n",
    "alpha = lassoCV.alpha_\n",
    "lasso = Lasso(alpha,max_iter=20000,normalize=False)\n",
    "pred = cross_val_predict(lasso, data_abs.loc[:, selected_otus], hna, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²_cv: 0.928038799058\n"
     ]
    }
   ],
   "source": [
    "r2_final = get_r2(pred,hna)   \n",
    "print('R²_cv: ' + str(r2_final) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Otu000027    0.973333\n",
       "Otu000057    0.953333\n",
       "Otu000267    0.880000\n",
       "Otu000128    0.846667\n",
       "Otu000203    0.803333\n",
       "Otu001749    0.743333\n",
       "Otu000048    0.736667\n",
       "Otu000043    0.700000\n",
       "Otu000614    0.693333\n",
       "Otu000474    0.663333\n",
       "Otu000005    0.663333\n",
       "Otu000058    0.636667\n",
       "Otu000168    0.610000\n",
       "Otu000025    0.606667\n",
       "Otu000109    0.603333\n",
       "Otu000004    0.583333\n",
       "Otu000123    0.580000\n",
       "Otu000176    0.560000\n",
       "Otu000173    0.546667\n",
       "Otu000098    0.546667\n",
       "Otu000050    0.523333\n",
       "Otu000084    0.516667\n",
       "Otu000029    0.513333\n",
       "Otu000344    0.500000\n",
       "Otu000011    0.486667\n",
       "Otu000292    0.483333\n",
       "Otu000009    0.473333\n",
       "Otu000124    0.463333\n",
       "Otu000017    0.456667\n",
       "Otu000563    0.446667\n",
       "Otu000782    0.446667\n",
       "Otu000047    0.440000\n",
       "Otu000016    0.430000\n",
       "Otu000219    0.423333\n",
       "Otu000067    0.423333\n",
       "Otu000227    0.413333\n",
       "Otu000615    0.400000\n",
       "Otu000985    0.396667\n",
       "Otu000487    0.393333\n",
       "Otu000190    0.386667\n",
       "Otu000112    0.383333\n",
       "Otu000030    0.383333\n",
       "Otu000101    0.363333\n",
       "Otu001267    0.356667\n",
       "Otu000264    0.343333\n",
       "Otu000041    0.340000\n",
       "Otu000217    0.340000\n",
       "Otu000590    0.336667\n",
       "Otu000644    0.336667\n",
       "Otu000040    0.333333\n",
       "Otu000917    0.333333\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(optimal_scores_prod)\n",
    "optimal_scores_prod.to_csv('HNA_selectedOTUs_prod_stand_abun_remov' + str(abun)+'_R2'+str(r2_final)+'.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
